# Video-Transcriber

Локальное приложение для транскрибации видео и аудио файлов с поддержкой диаризации спикеров.

## Возможности

- Транскрибация видео и аудио файлов (MP4, MKV, AVI, MOV, MP3, WAV, FLAC, OGG, M4A)
- Автоматическое определение языка (русский, английский и другие)
- Опциональная диаризация спикеров (определение кто говорит)
- Поддержка длинных записей (2+ часа, 2-6 GB файлы)
- Полностью локальная обработка — никакие данные не отправляются в интернет
- Автоматическое определение GPU и оптимальных настроек

## Требования

- Windows 10/11
- Python 3.11+
- NVIDIA GPU с CUDA (рекомендуется, но не обязательно)
  - RTX 3090 / RTX 4090 — все модели, максимальная скорость
  - GTX 1080 / RTX 2080 — большинство моделей
  - Работает и на CPU, но медленнее

## Установка

```bash
# Клонировать репозиторий
git clone https://github.com/kophysty/Video-Transcriber.git
cd Video-Transcriber

# Создать виртуальное окружение
python -m venv .venv
.venv\Scripts\activate

# Установить PyTorch с CUDA
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu124

# Установить остальные зависимости
pip install -r requirements.txt
```

## Запуск

```bash
python main.py
```

## Модели

При первом запуске нужно скачать модель Whisper. Рекомендуемые модели:

| Модель | VRAM | Качество | Скорость |
|--------|------|----------|----------|
| large-v3-turbo | ~3 GB | Отличное | Очень быстро |
| large-v3 | ~5 GB | Лучшее | Быстро |
| medium | ~2.5 GB | Хорошее | Быстро |
| small | ~1 GB | Приемлемое | Очень быстро |

Для диаризации спикеров дополнительно нужна модель pyannote (требует бесплатный HuggingFace токен).

## Форматы вывода

- **JSON** — полные данные с метаданными, word-level timestamps, спикерами
- **SRT** — субтитры для видеоплееров
- **VTT** — субтитры для веб
- **TXT** — простой текст с таймстампами

## Лицензия

MIT
